{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "name": "",
  "signature": "sha256:9437b2a7f33f0d450b33a9c72e3d5890cd95ec645d4798bd6eda4c88df192b4f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Tutorial: setting up a toy simulation\n",
      "=====================================\n",
      "\n",
      "In this tiny tutorial, we will perform all the necessary steps to set up a posterior distribution and a Gibbs sampler which is then used to sample from it. After, we discuss some elementary analysis of the samples."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "All information required for infering chromatin structures using BIOCHROSE is contained in `.ini`-like configuration files, the content of which is described elsewhere. As a first step to launching a toy BIOCHROSE simulation, we parse a configuration file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ensemble_hic.setup_functions import parse_config_file\n",
      "settings = parse_config_file('doc_config.cfg')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`settings` now is a dictionary of dictionary, in which the keys of the first layer are the section titles, that is,"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print settings.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['weights_hmc', 'data_filtering', 'sphere_prior', 'nonbonded_prior', 'forward_model', 'norm_prior', 'general', 'replica', 'initial_state', 'backbone_prior', 'structures_hmc']\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "and the keys of the second layer the parameters set in a single section, e.g.,"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print settings['general'].keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['error_model', 'data_file', 'variables', 'output_folder', 'n_beads', 'n_structures']\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "All values are parsed as strings, so at the moment, some care has to be taken; for example, `boolean` values must be either `True` or `False` with exactly that capitalization.\n",
      "We next create the central object in ISD, namely the posterior distribution, according to the settings we just loaded:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ensemble_hic.setup_functions import make_posterior\n",
      "posterior = make_posterior(settings)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IOError",
       "evalue": "[Errno 2] No such file or directory: '/home/simeon/projects/ensemble_hic/data/hairpin_s/hairpin_s_fwm_poisson_ssl3.txt'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-4-f614c116c456>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mensemble_hic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_posterior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mposterior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_posterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/home/simeoncarstens/.local/lib/python2.7/site-packages/ensemble_hic-0.1-py2.7-linux-x86_64.egg/ensemble_hic/setup_functions.pyc\u001b[0m in \u001b[0;36mmake_posterior\u001b[0;34m(settings)\u001b[0m\n\u001b[1;32m     90\u001b[0m                                  \u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data_filtering'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                                  \u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'general'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data_file'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                                  n_structures, bead_radii)\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'norm'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'general'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'variables'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         priors.update(norm_prior=make_norm_prior(settings['norm_prior'],\n",
        "\u001b[0;32m/home/simeoncarstens/.local/lib/python2.7/site-packages/ensemble_hic-0.1-py2.7-linux-x86_64.egg/ensemble_hic/setup_functions.pyc\u001b[0m in \u001b[0;36mmake_likelihood\u001b[0;34m(forward_model_params, error_model, data_filtering_params, data_file, n_structures, bead_radii)\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlikelihoods\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLikelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_filtering_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m     \u001b[0mcd_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_model_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'contact_distance_factor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0mcontact_distances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbead_radii\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbead_radii\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcd_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/simeoncarstens/.local/lib/python2.7/site-packages/ensemble_hic-0.1-py2.7-linux-x86_64.egg/ensemble_hic/setup_functions.pyc\u001b[0m in \u001b[0;36mparse_data\u001b[0;34m(data_file, data_filtering_params)\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0mignore_seq_nbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_filtering_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ignore_sequential_neighbors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0minclude_zero_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_filtering_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'include_zero_counts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minclude_zero_counts\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'False'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin)\u001b[0m\n\u001b[1;32m    801\u001b[0m                 \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m                 \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'U'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m                 \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/home/simeon/projects/ensemble_hic/data/hairpin_s/hairpin_s_fwm_poisson_ssl3.txt'"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `posterior` object now holds all likelihoods and priors we specified via the configuration file. Next, we create an initial state for the Markov chain we are going to construct later:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ensemble_hic.setup_functions import setup_weights, setup_initial_state\n",
      "settings['initial_state']['weights'] = setup_weights(settings)\n",
      "initial_state = setup_initial_state(settings['initial_state'], posterior)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The initial state holds initial values for the variables of the posterior distribution in its `variables` property:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(initial_state.variables['structures'])\n",
      "print initial_state.variables['structures'].shape\n",
      "print initial_state.variables['norm']"
     ],
     "language": "python",
     "metadata": {
      "scrolled": true
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The variable `structures` is a 1D NumPy array of length `n_structures x n_beads x 3` and variable `norm`, denoting the the scaling factor $\\alpha$, is some `float`.\n",
      "\n",
      "The next step is now to set up the samplers for each variable:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ensemble_hic.setup_functions import make_subsamplers\n",
      "subsamplers = make_subsamplers(posterior, initial_state.variables, settings['structures_hmc'], settings['weights_hmc'])\n",
      "print subsamplers"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have a Hybrid Monte Carlo sampler for the bead coordinates in the `structures` variable and an object which wraps a NumPy function to sample from a Gamma distribution which is the conditional distribution of the scaling factor."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, we need to set up the Gibbs sampler:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from binf.samplers.gibbs import GibbsSampler\n",
      "sampler = GibbsSampler(posterior, initial_state, subsamplers)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we're ready to draw samples from the posterior distribution (might take a while, $\\sim 3$ minutes on my laptop):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from copy import deepcopy\n",
      "n_samples = 5000\n",
      "samples = []\n",
      "for i in range(n_samples):\n",
      "    samples.append(deepcopy(sampler.sample()))\n",
      "    if i % 100 == 0:\n",
      "        print '{}/{} samples drawn'.format(i, n_samples)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's check the trace of the negative log-posterior to get an idea whether the simulation converged:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "energies = map(lambda x: -posterior.log_prob(**x.variables), samples)\n",
      "plt.plot(energies[100:])\n",
      "plt.xlabel('# of MCMC samples')\n",
      "plt.ylabel('-log(posterior)')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You should see the negative logarithm of the posterior probability level off and fluctuate around some fixed average. The number of MCMC samples at which this happens should be discarded as a burn-in period, in which the Markov chain forgets its initial state. It is important to remember that in a production run with actual data, you should absolutely use Replica Exchange to speed up convergence - already in this example, it can easily take  $4000$ MCMC samples to reach equilibrium. Let's take a look at the sampled values for the scaling factor $\\alpha$:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist([x.variables['norm'] for x in samples[4000:]], bins=50)\n",
      "plt.xlabel(r'scaling factor $\\alpha$')\n",
      "plt.ylabel('count')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The histogram should be centered around a value of $\\sim 50$. To find out whether we correctly reproduce the contact data, let's look at a scatter plot of back-calculated (\"mock\") vs experimental data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fwm = posterior.likelihoods['ensemble_contacts'].forward_model\n",
      "exp_data = fwm.data_points[:,2]\n",
      "mock_data = fwm(**samples[-1].variables)\n",
      "plt.scatter(exp_data, mock_data)\n",
      "plt.xlabel('experimental contact counts')\n",
      "plt.ylabel('back-calculated contact counts')\n",
      "plt.plot((0, 1.1 * max(exp_data)), (0, 1.1 * max(exp_data)), ls='--', c='r')\n",
      "plt.gcf().gca().set_aspect('equal')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You should find a bunch of points with zero contact counts in both the models and the actual data and a cloud of points at around (50,50). The discrepancies are likely due to the highly artificial structures from which the simulated data were generated. How do the contact frequency matrices compare?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "n_beads = int(settings['general']['n_beads'])\n",
      "b1 = fwm.data_points[:,0]\n",
      "b2 = fwm.data_points[:,1]\n",
      "exp_m = np.zeros((n_beads, n_beads))\n",
      "exp_m[b1, b2] = exp_data\n",
      "exp_m[b2, b1] = exp_data\n",
      "mock_m = np.zeros((n_beads, n_beads))\n",
      "mock_m[b1, b2] = mock_data\n",
      "mock_m[b2, b1] = mock_data\n",
      "fig, (ax1, ax2) = plt.subplots(1,2)\n",
      "ax1.matshow(exp_m)\n",
      "ax1.set_title('experimental data')\n",
      "ax2.matshow(mock_m)\n",
      "ax2.set_title('mock data')\n",
      "fig.tight_layout()\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Not too bad, I hope! Note that the main, 1st and 2nd diagonal is missing, because these contacts were not taken into account. \n",
      "We can also take a look at the back-calculated contact matrices of the single states. To this end, we generate a posterior object for $n=1$ states and feed its forward model the coordinates of the single states of the $n=2$ model :"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "settings['general']['n_structures'] = '1'\n",
      "p_n1 = make_posterior(settings)\n",
      "fwm = p_n1.likelihoods['ensemble_contacts'].forward_model\n",
      "md1 = fwm(structures=samples[-1].variables['structures'][:3*n_beads], norm=1.0)\n",
      "md2 = fwm(structures=samples[-1].variables['structures'][3*n_beads:], norm=1.0)\n",
      "fig, (ax1, ax2) = plt.subplots(1,2)\n",
      "m1 = np.zeros((n_beads, n_beads))\n",
      "m1[b1,b2] = md1\n",
      "m1[b2,b1] = md1\n",
      "m2 = np.zeros((n_beads, n_beads))\n",
      "m2[b1,b2] = md2\n",
      "m2[b2,b1] = md2\n",
      "ax1.matshow(m1)\n",
      "ax1.set_title('1st state')\n",
      "ax2.matshow(m2)\n",
      "ax2.set_title('2nd state')\n",
      "fig.tight_layout()\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {
      "scrolled": true
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If the Markov chain reached its equibrium, you should see that one state assumes the hairpin conformation (one diagonal in the matrix) and the other the \"S\" conformation (two diagonals). To visualize this, let's write a PDB file of our multi-state model:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ensemble_hic.analysis_functions import write_ensemble\n",
      "write_ensemble(samples[-1].variables['structures'].reshape(-1,n_beads,3), '/tmp/ensemble.pdb')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This PDB file will be a multi-model file with $n=2$ models. It can be opened with, e.g., VMD or PyMol. Note that you don't neccessarily get 2D structures: both the hairpin and the \"S\" shape have, embedded in 3D space, different conformations which give rise to the same contact data.\n",
      "We can also create a VMD script, which will load the PDB file and choose a convenient graphical representation as beads:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from ensemble_hic.analysis_functions import write_VMD_script\n",
      "bead_radii = posterior.priors['nonbonded_prior'].forcefield.bead_radii\n",
      "write_VMD_script('/tmp/ensemble.pdb', bead_radii, '/tmp/show_ensemble.rc')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This can now be run with the command `vmd -e /tmp/show_ensemble.rc`."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}